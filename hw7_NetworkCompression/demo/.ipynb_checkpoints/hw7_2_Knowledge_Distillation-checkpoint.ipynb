{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5cFq_TgWlQ_"
   },
   "source": [
    "# Homework 7 - Network Compression (Knowledge Distillation)\n",
    "\n",
    "> Author: Arvin Liu (b05902127@ntu.edu.tw)\n",
    "\n",
    "è‹¥æœ‰ä»»ä½•å•é¡Œï¼Œæ­¡è¿ä¾†ä¿¡è‡³åŠ©æ•™ä¿¡ç®± ntu-ml-2020spring-ta@googlegroups.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpmQUZhukmqe",
    "outputId": "c9b30ae8-c2c5-4408-f86c-d2add6023ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission denied: https://drive.google.com/uc?id=19CzXudqN58R3D-1G8KeFWk8UDQwlb8is\n",
      "Maybe you need to change permission over 'Anyone with the link'?\n",
      "unzip:  cannot find or open food-11.zip, food-11.zip.zip or food-11.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip\n",
    "# Unzip the files\n",
    "!unzip -q food-11.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNiZCGrIYKdR"
   },
   "source": [
    "# Readme\n",
    "\n",
    "\n",
    "HW7çš„ä»»å‹™æ˜¯æ¨¡å‹å£“ç¸® - Neural Network Compressionã€‚\n",
    "\n",
    "Compressionæœ‰å¾ˆå¤šç¨®é–€æ´¾ï¼Œåœ¨é€™è£¡æˆ‘å€‘æœƒä»‹ç´¹ä¸Šèª²å‡ºç¾éçš„å…¶ä¸­å››ç¨®ï¼Œåˆ†åˆ¥æ˜¯:\n",
    "\n",
    "* çŸ¥è­˜è’¸é¤¾ Knowledge Distillation\n",
    "* ç¶²è·¯å‰ªæ Network Pruning\n",
    "* ç”¨å°‘é‡åƒæ•¸ä¾†åšCNN Architecture Design\n",
    "* åƒæ•¸é‡åŒ– Weight Quantization\n",
    "\n",
    "åœ¨é€™å€‹notebookä¸­æˆ‘å€‘æœƒä»‹ç´¹Knowledge Distillationï¼Œ\n",
    "è€Œæˆ‘å€‘æœ‰æä¾›å·²ç¶“å­¸ç¿’å¥½çš„å¤§modelæ–¹ä¾¿å¤§å®¶åšKnowledge Distillationã€‚\n",
    "è€Œæˆ‘å€‘ä½¿ç”¨çš„å°modelæ˜¯\"Architecture Design\"éçš„modelã€‚\n",
    "\n",
    "* Architecute Designåœ¨åŒç›®éŒ„ä¸­çš„hw7_Architecture_Design.ipynbã€‚\n",
    "* ä¸‹è¼‰pretrainedå¤§model(47.2M): https://drive.google.com/file/d/1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN/view?usp=sharing\n",
    "  * è«‹ä½¿ç”¨torchvisionæä¾›çš„ResNet18ï¼ŒæŠŠnum_classesæ”¹æˆ11å¾Œloadé€²å»å³å¯ã€‚(å¾Œé¢æœ‰ç¯„ä¾‹ã€‚)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XdzskhdEb65Z",
    "outputId": "a4e9074c-0a62-492b-d30d-8b2e8a9e2d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lJS0ApIyi7eZ2b3GMyGxjPShI8jXM2UC\n",
      "To: /content/hw7_Architecture_Design.ipynb\n",
      "100% 8.65k/8.65k [00:00<00:00, 25.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "# Loadé€²æˆ‘å€‘çš„Modelæ¶æ§‹(åœ¨hw7_Architecture_Design.ipynbå…§)\n",
    "!gdown --id '1lJS0ApIyi7eZ2b3GMyGxjPShI8jXM2UC' --output \"hw7_Architecture_Design.ipynb\"\n",
    "%run \"hw7_Architecture_Design.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdUtCxBBcH0B"
   },
   "source": [
    "Knowledge Distillation\n",
    "===\n",
    "\n",
    "<img src=\"https://i.imgur.com/H2aF7Rv.png=100x\" width=\"500px\">\n",
    "\n",
    "ç°¡å–®ä¸Šä¾†èªªå°±æ˜¯è®“å·²ç¶“åšå¾—å¾ˆå¥½çš„å¤§modelå€‘å»å‘Šè¨´å°model\"å¦‚ä½•\"å­¸ç¿’ã€‚\n",
    "è€Œæˆ‘å€‘å¦‚ä½•åšåˆ°é€™ä»¶äº‹æƒ…å‘¢? å°±æ˜¯åˆ©ç”¨å¤§modelé æ¸¬çš„logitsçµ¦å°modelç•¶ä½œæ¨™æº–å°±å¯ä»¥äº†ã€‚\n",
    "\n",
    "## ç‚ºç”šéº¼é€™æœƒwork?\n",
    "* ä¾‹å¦‚ç•¶dataä¸æ˜¯å¾ˆä¹¾æ·¨çš„æ™‚å€™ï¼Œå°ä¸€èˆ¬çš„modelä¾†èªªä»–æ˜¯å€‹noiseï¼Œåªæœƒå¹²æ“¾å­¸ç¿’ã€‚é€éå»å­¸ç¿’å…¶ä»–å¤§modelé æ¸¬çš„logitsæœƒæ¯”è¼ƒå¥½ã€‚\n",
    "* labelå’Œlabelä¹‹é–“å¯èƒ½æœ‰é—œé€£ï¼Œé€™å¯ä»¥å¼•å°å°modelå»å­¸ç¿’ã€‚ä¾‹å¦‚æ•¸å­—8å¯èƒ½å°±å’Œ6,9,0æœ‰é—œä¿‚ã€‚\n",
    "* å¼±åŒ–å·²ç¶“å­¸ç¿’ä¸éŒ¯çš„target(?)ï¼Œé¿å…è®“å…¶gradientå¹²æ“¾å…¶ä»–é‚„æ²’å­¸å¥½çš„taskã€‚\n",
    "\n",
    "\n",
    "## è¦æ€éº¼å¯¦ä½œ?\n",
    "* $Loss = \\alpha T^2 \\times KL(\\frac{\\text{Teacher's Logits}}{T} || \\frac{\\text{Student's Logits}}{T}) + (1-\\alpha)(\\text{Original Loss})$\n",
    "\n",
    "\n",
    "* ä»¥ä¸‹codeç‚ºç”šéº¼è¦å°studentä½¿ç”¨log_softmax: https://github.com/peterliht/knowledge-distillation-pytorch/issues/2\n",
    "* reference: [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "M-dSi_P-4les"
   },
   "outputs": [],
   "source": [
    "def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):\n",
    "    # ä¸€èˆ¬çš„Cross Entropy\n",
    "    # å¯¹åº”æŸå¤±å‡½æ•°å…¬å¼ä¸­çš„(1âˆ’ğ›¼)(Original Loss)\n",
    "    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "    # è®“logitsçš„log_softmaxå°ç›®æ¨™æ©Ÿç‡(teacherçš„logits/Tå¾Œsoftmax)åšKL Divergenceã€‚\n",
    "    # å¯¹åº”æŸå¤±å‡½æ•°å…¬å¼ä¸­çš„ğ¾ğ¿(Student's Logits/ğ‘‡||Teacher's Logits/ğ‘‡) Ã— ğ›¼ğ‘‡2\n",
    "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),\n",
    "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n",
    "     # å¯¹åº”æŸå¤±å‡½æ•°å…¬å¼ä¸­çš„ğ›¼ğ‘‡2Ã—ğ¾ğ¿(Teacher's Logitsğ‘‡||Student's Logitsğ‘‡)+(1âˆ’ğ›¼)(Original Loss)\n",
    "    return hard_loss + soft_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfnRoOt5VIze"
   },
   "source": [
    "# Data Processing\n",
    "\n",
    "æˆ‘å€‘çš„Datasetä½¿ç”¨çš„æ˜¯è·ŸHw3 - CNNåŒæ¨£çš„Datasetï¼Œå› æ­¤é€™å€‹å€å¡Šçš„Augmentation / Read Imageå¤§å®¶åƒè€ƒæˆ–ç›´æ¥æŠ„å°±å¥½ã€‚\n",
    "\n",
    "å¦‚æœæœ‰ä¸æœƒçš„è©±å¯ä»¥å›å»çœ‹Hw3çš„colabã€‚\n",
    "\n",
    "éœ€è¦æ³¨æ„çš„æ˜¯å¦‚æœè¦è‡ªå·±å¯«çš„è©±ï¼ŒAugmentçš„æ–¹æ³•æœ€å¥½ä½¿ç”¨æˆ‘å€‘çš„æ–¹æ³•ï¼Œé¿å…è¼¸å…¥æœ‰å·®ç•°å°è‡´Teacher Neté æ¸¬ä¸å¥½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ExdUvTRaVNOT"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_517/1411527255.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, folderName, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "        for img_path in sorted(glob(folderName + '/*.jpg')):\n",
    "            try:\n",
    "                # Get classIdx by parsing image path\n",
    "                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n",
    "            except:\n",
    "                # if inference mode (there's no answer), class_idx default 0\n",
    "                class_idx = 0\n",
    "\n",
    "            image = Image.open(img_path)\n",
    "            # Get File Descriptor\n",
    "            image_fp = image.fp\n",
    "            image.load()\n",
    "            # Close File Descriptor (or it'll reach OPEN_MAX)\n",
    "            image_fp.close()\n",
    "\n",
    "            self.data.append(image)\n",
    "            self.label.append(class_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label[idx]\n",
    "\n",
    "\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "testTransform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def get_dataloader(mode='training', batch_size=32):\n",
    "\n",
    "    assert mode in ['training', 'testing', 'validation']\n",
    "\n",
    "    dataset = MyDataset(\n",
    "        f'./food-11/{mode}',\n",
    "        transform=trainTransform if mode == 'training' else testTransform)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(mode == 'training'))\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACPwL9_JWceQ"
   },
   "source": [
    "# Pre-processing\n",
    "\n",
    "æˆ‘å€‘å·²ç¶“æä¾›TeacherNetçš„state_dictï¼Œå…¶æ¶æ§‹æ˜¯torchvisionæä¾›çš„ResNet18ã€‚\n",
    "\n",
    "è‡³æ–¼StudentNetçš„æ¶æ§‹å‰‡åœ¨hw7_Architecture_Design.ipynbä¸­ã€‚\n",
    "\n",
    "é€™è£¡æˆ‘å€‘ä½¿ç”¨çš„Optimizerç‚ºAdamWï¼Œæ²’æœ‰ç‚ºç”šéº¼ï¼Œå°±ç´”ç²¹æˆ‘æƒ³ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wzuuGvnbWkG8",
    "outputId": "ef85e024-a1c0-4b83-9cc6-ee67fdb507a0"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3c6ca1d848fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalid_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1080d2140fbd>\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(mode, batch_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         shuffle=(mode == 'training'))\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;31m# Cannot statically verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m--> 104\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# get dataloader\n",
    "train_dataloader = get_dataloader('training', batch_size=32)\n",
    "valid_dataloader = get_dataloader('validation', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZWdQtDtgoGCp"
   },
   "outputs": [],
   "source": [
    "!gdown --id '1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN' --output teacher_resnet18.bin\n",
    "\n",
    "teacher_net = models.resnet18(pretrained=False, num_classes=11).cuda()\n",
    "student_net = StudentNet(base=16).cuda()\n",
    "\n",
    "teacher_net.load_state_dict(torch.load(f'./teacher_resnet18.bin'))\n",
    "optimizer = optim.AdamW(student_net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wvc1W5yO2QaE"
   },
   "source": [
    "# Start Training\n",
    "\n",
    "* å‰©ä¸‹çš„æ­¥é©Ÿèˆ‡ä½ åœ¨åšHw3 - CNNçš„æ™‚å€™ä¸€æ¨£ã€‚\n",
    "\n",
    "## å°æé†’\n",
    "\n",
    "* torch.no_gradæ˜¯æŒ‡æ¥ä¸‹ä¾†çš„é‹ç®—æˆ–è©²tensorä¸éœ€è¦ç®—gradientã€‚\n",
    "* model.eval()èˆ‡model.train()å·®åœ¨æ–¼Batchnormè¦ä¸è¦ç´€éŒ„ï¼Œä»¥åŠè¦ä¸è¦åšDropoutã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-TzmWtT62Qmy"
   },
   "outputs": [],
   "source": [
    "def run_epoch(dataloader, update=True, alpha=0.5):\n",
    "    total_num, total_hit, total_loss = 0, 0, 0\n",
    "    for now_step, batch_data in enumerate(dataloader):\n",
    "        # æ¸…ç©º optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # è™•ç† input\n",
    "        inputs, hard_labels = batch_data\n",
    "        inputs = inputs.cuda()\n",
    "        hard_labels = torch.LongTensor(hard_labels).cuda()\n",
    "        # å› ç‚ºTeacheræ²’æœ‰è¦backpropï¼Œæ‰€ä»¥æˆ‘å€‘ä½¿ç”¨torch.no_grad\n",
    "        # å‘Šè¨´torchä¸è¦æš«å­˜ä¸­é–“å€¼(å»åšbackprop)ä»¥æµªè²»è¨˜æ†¶é«”ç©ºé–“ã€‚\n",
    "        with torch.no_grad():\n",
    "            soft_labels = teacher_net(inputs)\n",
    "\n",
    "        if update:\n",
    "            logits = student_net(inputs)\n",
    "            # ä½¿ç”¨æˆ‘å€‘ä¹‹å‰æ‰€å¯«çš„èåˆsoft label&hard labelçš„lossã€‚\n",
    "            # T=20æ˜¯åŸå§‹è«–æ–‡çš„åƒæ•¸è¨­å®šã€‚\n",
    "            loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "        else:\n",
    "            # åªæ˜¯ç®—validation accçš„è©±ï¼Œå°±é–‹no_gradç¯€çœç©ºé–“ã€‚\n",
    "            with torch.no_grad():\n",
    "                logits = student_net(inputs)\n",
    "                loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
    "            \n",
    "        total_hit += torch.sum(torch.argmax(logits, dim=1) == hard_labels).item()\n",
    "        total_num += len(inputs)\n",
    "\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    return total_loss / total_num, total_hit / total_num\n",
    "\n",
    "\n",
    "# TeacherNetæ°¸é éƒ½æ˜¯Eval mode.\n",
    "teacher_net.eval()\n",
    "now_best_acc = 0\n",
    "for epoch in range(200):\n",
    "    student_net.train()\n",
    "    train_loss, train_acc = run_epoch(train_dataloader, update=True)\n",
    "    student_net.eval()\n",
    "    valid_loss, valid_acc = run_epoch(valid_dataloader, update=False)\n",
    "\n",
    "    # å­˜ä¸‹æœ€å¥½çš„modelã€‚\n",
    "    if valid_acc > now_best_acc:\n",
    "        now_best_acc = valid_acc\n",
    "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
    "    print('epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(\n",
    "        epoch, train_loss, train_acc, valid_loss, valid_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GObCiGNtPkZ"
   },
   "source": [
    "# Inference\n",
    "\n",
    "åŒHw3ï¼Œè«‹åƒè€ƒè©²ä½œæ¥­:)ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIcblvbUCTOP"
   },
   "source": [
    "# Q&A\n",
    "\n",
    "æœ‰ä»»ä½•å•é¡ŒNetwork Compressionçš„å•é¡Œå¯ä»¥å¯„ä¿¡åˆ°b05902127@ntu.edu.tw / ntu-ml-2020spring-ta@googlegroups.comã€‚\n",
    "\n",
    "æ™‚é–“å…è¨±çš„è©±æˆ‘æœƒæ›´æ–°åœ¨é€™è£¡ã€‚"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "hw7_Knowledge_Distillation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
